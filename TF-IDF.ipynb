{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Representations (TF-IDF) : Sentence-Document  Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- Importing Various packages ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from time import time\n",
    "import operator\n",
    "import scipy.stats as scipy\n",
    "\n",
    "\n",
    "# --- NLTK PACKAGE ---\n",
    "import nltk\n",
    "# Tokenizers\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# --- GENSIM PACKAGE ---\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, doc2vec, Doc2Vec\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_json('squad_train_doc.json')\n",
    "data_train.rename(columns={'passages': 'documents'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segregating Data to form a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>questions</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>[[What is the Grotto at Notre Dame?, To whom d...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ ...</td>\n",
       "      <td>[[In what city and state did Beyonce  grow up?...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Montana i/mɒnˈtænə/ is a state in the Western...</td>\n",
       "      <td>[[What is its rank in popularion?, What is the...</td>\n",
       "      <td>Montana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The phrase \"in whole or in part\" has been sub...</td>\n",
       "      <td>[[Which phrase is especially contentious withi...</td>\n",
       "      <td>Genocide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The emergence of resistance of bacteria to an...</td>\n",
       "      <td>[[What is the purpose of antibiotic treatment?...</td>\n",
       "      <td>Antibiotics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  [Architecturally, the school has a Catholic ch...   \n",
       "1  [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ ...   \n",
       "2  [Montana i/mɒnˈtænə/ is a state in the Western...   \n",
       "3  [The phrase \"in whole or in part\" has been sub...   \n",
       "4  [The emergence of resistance of bacteria to an...   \n",
       "\n",
       "                                           questions                     title  \n",
       "0  [[What is the Grotto at Notre Dame?, To whom d...  University_of_Notre_Dame  \n",
       "1  [[In what city and state did Beyonce  grow up?...                   Beyoncé  \n",
       "2  [[What is its rank in popularion?, What is the...                   Montana  \n",
       "3  [[Which phrase is especially contentious withi...                  Genocide  \n",
       "4  [[What is the purpose of antibiotic treatment?...               Antibiotics  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_compact_dataframe():\n",
    "    context_list = []\n",
    "    question_list = []\n",
    "    for doc in data_train.documents:\n",
    "        context_list.append(get_each_context_each_questionSet(doc)[0])\n",
    "        question_list.append(get_each_context_each_questionSet(doc)[1])\n",
    "    return context_list, question_list\n",
    "\n",
    "def get_each_context_each_questionSet(document):\n",
    "    each_doc_context_list = [document[i]['context'] for i in range(len(document))]\n",
    "    each_doc_question_list = [document[i]['questions'] for i in range(len(document))]\n",
    "    return  each_doc_context_list, each_doc_question_list\n",
    "\n",
    "context_list, question_list = get_compact_dataframe()[0], get_compact_dataframe()[1]\n",
    "dataframe = pd.DataFrame({'title':data_train.title, 'context':context_list, 'questions': question_list})\n",
    "list_all_context_per_doc = [' '.join(context_list[i]) for i in range(len(context_list))]\n",
    "list_all_questions_per_doc = [sum(question_list[i],[]) for i in range(len(question_list))]\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "tokenized_context_and_questions = []\n",
    "\n",
    "for context, question in zip(list_all_context_per_doc, list_all_questions_per_doc):\n",
    "    context_words = [word for word in word_tokenize(context) if word not in stop_words]\n",
    "    question_words = [word for word in word_tokenize(' '.join(question)) if word not in stop_words]\n",
    "    tokenized_context_and_questions.append(context_words + question_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF MODEL\n",
    "''' Accepts a list of tokenized words of context plus questions as its training data.\n",
    "'''\n",
    "dictionary = corpora.Dictionary(tokenized_context_and_questions)\n",
    "dictionary.save('/tmp/squad.dict') \n",
    "raw_corpus = [dictionary.doc2bow(each_doc) for each_doc in tokenized_context_and_questions]\n",
    "corpora.MmCorpus.serialize('/tmp/squad.mm', raw_corpus)\n",
    "corpus = corpora.MmCorpus('/tmp/squad.mm')\n",
    "tfidf = models.TfidfModel(corpus) \n",
    "corpus_tfidf = tfidf[corpus]\n",
    "TFIDF_model = similarities.MatrixSimilarity(corpus_tfidf)\n",
    "TFIDF_model.save('/tmp/squad.TFIDF_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TFIDF_model.save('TFIDF.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_loaded = gensim.models.Doc2Vec.load('TFIDF.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence - Document Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = 'What is Grotto at Notre Dame?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Score_TFIDF</th>\n",
       "      <th>Rank_TFIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0.611371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Order_of_the_British_Empire</td>\n",
       "      <td>0.063304</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Paris</td>\n",
       "      <td>0.046176</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Appalachian_Mountains</td>\n",
       "      <td>0.029890</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>Humanism</td>\n",
       "      <td>0.016467</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Gothic_architecture</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Neoclassical_architecture</td>\n",
       "      <td>0.011725</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Dominican_Order</td>\n",
       "      <td>0.010206</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Universal_Studios</td>\n",
       "      <td>0.010030</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Hanover</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Document  Score_TFIDF  Rank_TFIDF\n",
       "0       University_of_Notre_Dame     0.611371           1\n",
       "166  Order_of_the_British_Empire     0.063304           2\n",
       "327                        Paris     0.046176           3\n",
       "340        Appalachian_Mountains     0.029890           4\n",
       "435                     Humanism     0.016467           5\n",
       "237          Gothic_architecture     0.012007           6\n",
       "338    Neoclassical_architecture     0.011725           7\n",
       "287              Dominican_Order     0.010206           8\n",
       "55             Universal_Studios     0.010030           9\n",
       "132                      Hanover     0.006234          10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF(query).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Accepts a question(query) to implement TF-IDF Model.\n",
    "    Takes a query and word tokenizes it. \n",
    "    'raw_corpus_query' - The word-tokenized query is compared with the dictionary used to train the document. \n",
    "        'corpus_query' - The word-id and word is converted into a corpus.The corpus is then fed to the TF-IDF model.\n",
    "    'similarity_table' - Stores the TF-IDF weights which are then used to get most similiar documents.\n",
    "               'ranks' - Scipy method which compares the similarity weights and sorts is accordingly.\n",
    "    \n",
    "    --> Returns a dataframe with Document name, Score and Rank\n",
    "'''\n",
    "\n",
    "def TFIDF(query): \n",
    "    query_1 = []\n",
    "    query_1.append(word_tokenize(query))\n",
    "    raw_corpus_query = [dictionary.doc2bow(word) for word in query_1]\n",
    "    corpora.MmCorpus.serialize('/tmp/query3.mm',raw_corpus_query)\n",
    "    corpus_query = corpora.MmCorpus('/tmp/query3.mm')\n",
    "    similarity_table = TFIDF_model[corpus_query]\n",
    "    ranks = scipy.rankdata(similarity_table, method = 'max')\n",
    "    similarity_table = list(np.array(similarity_table).flatten())\n",
    "    TFIDF_dataframe = pd.DataFrame({'Document':data_train.title, 'Score_TFIDF':similarity_table}).sort_values(by=['Score_TFIDF'],ascending=False)\n",
    "    TFIDF_dataframe['Rank_TFIDF'] = [i for i in range(1, len(data_train.title)+1)]\n",
    "    return TFIDF_dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
